{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text : 5571910 characters\n"
     ]
    }
   ],
   "source": [
    "with open('data\\shakespeare.txt', 'rb') as f:\n",
    "    text=f.read().decode(encoding='utf-8')\n",
    "# cup the text\n",
    "text=text[11532 :]\n",
    "#print(text[:250])\n",
    "print('length of text : {} characters'.format(len(text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 unique charachters\n",
      "{\n",
      " '\\n':   0\n",
      " '\\r':   1\n",
      " ' ' :   2\n",
      " '!' :   3\n",
      " '\"' :   4\n",
      " '&' :   5\n",
      " \"'\" :   6\n",
      " '(' :   7\n",
      " ')' :   8\n",
      " ',' :   9\n",
      " '-' :  10\n",
      " '.' :  11\n",
      " '0' :  12\n",
      " '1' :  13\n",
      " '2' :  14\n",
      " '3' :  15\n",
      " '4' :  16\n",
      " '5' :  17\n",
      " '6' :  18\n",
      " '7' :  19\n",
      "...\n",
      "\n",
      "'\\r\\n\\r\\n\\r\\n\\r\\n     '====> charachter map to int ====>[ 1  0  1  0  1  0  1  0  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2 13]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab=sorted(set(text))\n",
    "\n",
    "print(\"{} unique charachters\".format(len(vocab)))\n",
    "\n",
    "char2idx= {unique:idx for idx, unique in enumerate(vocab)}\n",
    "idx2char= np.array(vocab)\n",
    "\n",
    "text_as_int=np.array([char2idx[char] for char in text])\n",
    "\n",
    "print('{')\n",
    "\n",
    "for char , _ in zip(char2idx, range(20)):\n",
    "    print(' {:4s}: {:3d}'.format(repr(char), char2idx[char]))\n",
    "\n",
    "print('...\\n')\n",
    "\n",
    "print('{}====> charachter map to int ====>{}'\n",
    "    .format(repr(text[:13]), text_as_int[:30]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq_length=100\n",
    "examples_per_epoch=len(text) // (seq_length +1)\n",
    "char_datasets=tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_datasets.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebcd9c1f586b857157fbd284fb4f94b3e333b2edea4e5c38ac1f594b892f68c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
